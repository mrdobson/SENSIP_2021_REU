{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_qnn_2class_loop.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOeaFtSW71cbew4tkqe0WeQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrdobson/SENSIP_2021_REU/blob/main/mnist_qnn_2class_loop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruCaEYK6d9E3",
        "outputId": "6998f7b9-0eb0-42f2-a338-1cc868241f4c"
      },
      "source": [
        "!pip install qiskit\n",
        "!pip install qiskit_machine_learning\n",
        "!pip install pylatexenc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: qiskit in ./anaconda3/envs/quantum/lib/python3.9/site-packages (0.25.0)\n",
            "Requirement already satisfied: qiskit-terra==0.17.0 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit) (0.17.0)\n",
            "Requirement already satisfied: qiskit-aqua==0.9.0 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit) (0.9.0)\n",
            "Requirement already satisfied: qiskit-ignis==0.6.0 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit) (0.6.0)\n",
            "Requirement already satisfied: qiskit-ibmq-provider==0.12.2 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit) (0.12.2)\n",
            "Requirement already satisfied: qiskit-aer==0.8.0 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit) (0.8.0)\n",
            "Requirement already satisfied: numpy>=1.16.3 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-aer==0.8.0->qiskit) (1.19.5)\n",
            "Requirement already satisfied: pybind11>=2.6 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-aer==0.8.0->qiskit) (2.6.2)\n",
            "Requirement already satisfied: scipy>=1.0 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-aer==0.8.0->qiskit) (1.6.1)\n",
            "Requirement already satisfied: docplex<=2.20.204 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-aqua==0.9.0->qiskit) (2.20.204)\n",
            "Requirement already satisfied: scikit-learn<=0.24.1,>=0.20.0 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-aqua==0.9.0->qiskit) (0.24.1)\n",
            "Requirement already satisfied: quandl<=3.6.0 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-aqua==0.9.0->qiskit) (3.6.0)\n",
            "Requirement already satisfied: sympy<=1.7.1,>=1.3 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-aqua==0.9.0->qiskit) (1.7.1)\n",
            "Requirement already satisfied: setuptools>=40.1.0 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-aqua==0.9.0->qiskit) (52.0.0.post20210125)\n",
            "Requirement already satisfied: dlx<=1.0.4 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-aqua==0.9.0->qiskit) (1.0.4)\n",
            "Requirement already satisfied: retworkx<=0.8.0,>=0.7.0 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-aqua==0.9.0->qiskit) (0.8.0)\n",
            "Requirement already satisfied: pandas<=1.2.3 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-aqua==0.9.0->qiskit) (1.2.3)\n",
            "Requirement already satisfied: psutil<=5.8.0,>=5 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-aqua==0.9.0->qiskit) (5.8.0)\n",
            "Requirement already satisfied: yfinance<=0.1.55 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-aqua==0.9.0->qiskit) (0.1.55)\n",
            "Requirement already satisfied: fastdtw<=0.3.4 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-aqua==0.9.0->qiskit) (0.3.4)\n",
            "Requirement already satisfied: h5py<=3.1.0 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-aqua==0.9.0->qiskit) (3.1.0)\n",
            "Requirement already satisfied: websockets>=8 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-ibmq-provider==0.12.2->qiskit) (8.1)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-ibmq-provider==0.12.2->qiskit) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-ibmq-provider==0.12.2->qiskit) (2.8.1)\n",
            "Requirement already satisfied: requests>=2.19 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-ibmq-provider==0.12.2->qiskit) (2.25.1)\n",
            "Requirement already satisfied: requests-ntlm>=1.1.0 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-ibmq-provider==0.12.2->qiskit) (1.1.0)\n",
            "Requirement already satisfied: nest-asyncio!=1.1.0,>=1.0.0 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-ibmq-provider==0.12.2->qiskit) (1.5.1)\n",
            "Requirement already satisfied: dill>=0.3 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-terra==0.17.0->qiskit) (0.3.3)\n",
            "Requirement already satisfied: fastjsonschema>=2.10 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-terra==0.17.0->qiskit) (2.15.0)\n",
            "Requirement already satisfied: python-constraint>=1.4 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-terra==0.17.0->qiskit) (1.4.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-terra==0.17.0->qiskit) (3.2.0)\n",
            "Requirement already satisfied: ply>=3.10 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-terra==0.17.0->qiskit) (3.11)\n",
            "Requirement already satisfied: six in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from docplex<=2.20.204->qiskit-aqua==0.9.0->qiskit) (1.15.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from jsonschema>=2.6->qiskit-terra==0.17.0->qiskit) (0.17.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from jsonschema>=2.6->qiskit-terra==0.17.0->qiskit) (21.2.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from pandas<=1.2.3->qiskit-aqua==0.9.0->qiskit) (2021.1)\n",
            "Requirement already satisfied: inflection>=0.3.1 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from quandl<=3.6.0->qiskit-aqua==0.9.0->qiskit) (0.5.1)\n",
            "Requirement already satisfied: more-itertools in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from quandl<=3.6.0->qiskit-aqua==0.9.0->qiskit) (8.7.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from requests>=2.19->qiskit-ibmq-provider==0.12.2->qiskit) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from requests>=2.19->qiskit-ibmq-provider==0.12.2->qiskit) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from requests>=2.19->qiskit-ibmq-provider==0.12.2->qiskit) (2.10)\n",
            "Requirement already satisfied: ntlm-auth>=1.0.2 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.12.2->qiskit) (1.5.0)\n",
            "Requirement already satisfied: cryptography>=1.3 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.12.2->qiskit) (3.4.7)\n",
            "Requirement already satisfied: cffi>=1.12 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.12.2->qiskit) (1.14.5)\n",
            "Requirement already satisfied: pycparser in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.12.2->qiskit) (2.20)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from scikit-learn<=0.24.1,>=0.20.0->qiskit-aqua==0.9.0->qiskit) (2.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from scikit-learn<=0.24.1,>=0.20.0->qiskit-aqua==0.9.0->qiskit) (1.0.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from sympy<=1.7.1,>=1.3->qiskit-aqua==0.9.0->qiskit) (1.2.1)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from yfinance<=0.1.55->qiskit-aqua==0.9.0->qiskit) (0.0.9)\n",
            "Requirement already satisfied: lxml>=4.5.1 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from yfinance<=0.1.55->qiskit-aqua==0.9.0->qiskit) (4.6.3)\n",
            "Requirement already satisfied: qiskit_machine_learning in ./anaconda3/envs/quantum/lib/python3.9/site-packages (0.1.0)\n",
            "Requirement already satisfied: sparse in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit_machine_learning) (0.12.0)\n",
            "Requirement already satisfied: qiskit-terra>=0.17.0 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit_machine_learning) (0.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit_machine_learning) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit_machine_learning) (0.24.1)\n",
            "Requirement already satisfied: fastdtw in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit_machine_learning) (0.3.4)\n",
            "Requirement already satisfied: scipy>=1.4 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit_machine_learning) (1.6.1)\n",
            "Requirement already satisfied: setuptools>=40.1.0 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit_machine_learning) (52.0.0.post20210125)\n",
            "Requirement already satisfied: psutil>=5 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit_machine_learning) (5.8.0)\n",
            "Requirement already satisfied: python-constraint>=1.4 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-terra>=0.17.0->qiskit_machine_learning) (1.4.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-terra>=0.17.0->qiskit_machine_learning) (3.2.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.10 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-terra>=0.17.0->qiskit_machine_learning) (2.15.0)\n",
            "Requirement already satisfied: retworkx>=0.8.0 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-terra>=0.17.0->qiskit_machine_learning) (0.8.0)\n",
            "Requirement already satisfied: dill>=0.3 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-terra>=0.17.0->qiskit_machine_learning) (0.3.3)\n",
            "Requirement already satisfied: ply>=3.10 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-terra>=0.17.0->qiskit_machine_learning) (3.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-terra>=0.17.0->qiskit_machine_learning) (2.8.1)\n",
            "Requirement already satisfied: sympy>=1.3 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from qiskit-terra>=0.17.0->qiskit_machine_learning) (1.7.1)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from jsonschema>=2.6->qiskit-terra>=0.17.0->qiskit_machine_learning) (0.17.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from jsonschema>=2.6->qiskit-terra>=0.17.0->qiskit_machine_learning) (21.2.0)\n",
            "Requirement already satisfied: six>=1.11.0 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from jsonschema>=2.6->qiskit-terra>=0.17.0->qiskit_machine_learning) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from scikit-learn>=0.20.0->qiskit_machine_learning) (2.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from scikit-learn>=0.20.0->qiskit_machine_learning) (1.0.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from sympy>=1.3->qiskit-terra>=0.17.0->qiskit_machine_learning) (1.2.1)\n",
            "Requirement already satisfied: numba>=0.49 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from sparse->qiskit_machine_learning) (0.53.1)\n",
            "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in ./anaconda3/envs/quantum/lib/python3.9/site-packages (from numba>=0.49->sparse->qiskit_machine_learning) (0.36.0)\n",
            "Requirement already satisfied: pylatexenc in ./anaconda3/envs/quantum/lib/python3.9/site-packages (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp7N5VAuhYz5"
      },
      "source": [
        "# not all of these are critical, but to be safe just including everything for now\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import torch\n",
        "import qiskit\n",
        "\n",
        "from torch import tensor\n",
        "from torch import cat, no_grad\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch.nn import (Module, Conv2d, Linear, Dropout2d, NLLLoss, CrossEntropyLoss,\n",
        "                      MaxPool2d, Flatten, Sequential, ReLU)\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "from qiskit import Aer, QuantumCircuit\n",
        "from qiskit.opflow import Z, I, StateFn, PauliSumOp, AerPauliExpectation, ListOp, Gradient\n",
        "from qiskit.utils import QuantumInstance\n",
        "from qiskit.circuit import Parameter\n",
        "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
        "from qiskit.algorithms.optimizers import COBYLA, L_BFGS_B, ADAM\n",
        "\n",
        "from qiskit_machine_learning.neural_networks import TwoLayerQNN, CircuitQNN\n",
        "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier, VQC\n",
        "from qiskit_machine_learning.algorithms.regressors import NeuralNetworkRegressor, VQR\n",
        "\n",
        "from qiskit_machine_learning.connectors import TorchConnector\n",
        "from qiskit_machine_learning.exceptions import QiskitMachineLearningError\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofGiwiThhb14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a773cd80-ebdb-4cc6-8c56-78922849965e"
      },
      "source": [
        "qi_qasm = QuantumInstance(Aer.get_backend('qasm_simulator'), shots=1024)\n",
        "qi_sv = QuantumInstance(Aer.get_backend('statevector_simulator'))\n",
        "\n",
        "# select whether to run on GPU or not\n",
        "gpu = True\n",
        "\n",
        "# predefine number of epochs to train over\n",
        "epochs = 7\n",
        "\n",
        "# if use_cuda == true then use GPU accel functions\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "print('CUDA available:', use_cuda)\n",
        "\n",
        "if use_cuda and gpu:\n",
        "    device = torch.device('cuda')\n",
        "    print('Training on GPU...')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print('Training on CPU...')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA available: True\n",
            "Training on GPU...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqGhMX_Ahf6N",
        "outputId": "2751c525-ae4f-46b6-943e-7363d75ff9ed"
      },
      "source": [
        "# full data set range\n",
        "data_set = list(range(0,10))\n",
        "print(data_set)\n",
        "\n",
        "QC_outputs = ['000', '001', '010', '011', '100', '101', '110', '111']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rug1pfPPgbcb"
      },
      "source": [
        "# Quantum Circuit Options"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHV5pAnXo2Wd"
      },
      "source": [
        "class QuantumCircuit:\n",
        "    \"\"\" \n",
        "    This class provides a simple interface for interaction \n",
        "    with the quantum circuit \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, n_qubits, backend, shots):\n",
        "        # --- Circuit definition ---\n",
        "        self._circuit = qiskit.QuantumCircuit(n_qubits)\n",
        "        \n",
        "        all_qubits = [i for i in range(n_qubits)]\n",
        "                \n",
        "            \n",
        "        self.theta_0 = qiskit.circuit.Parameter('theta0')\n",
        "        self.theta_1 = qiskit.circuit.Parameter('theta1')\n",
        "        self.theta_2 = qiskit.circuit.Parameter('theta2')\n",
        "        self.theta_3 = qiskit.circuit.Parameter('theta3')\n",
        "        self.theta_4 = qiskit.circuit.Parameter('theta4')\n",
        "        self.theta_5 = qiskit.circuit.Parameter('theta5')\n",
        "        self.theta_6 = qiskit.circuit.Parameter('theta6')\n",
        "\n",
        "        \n",
        "        self._circuit.h(all_qubits)\n",
        "        self._circuit.barrier()\n",
        "        self._circuit.ry(self.theta_0, all_qubits)\n",
        "        self._circuit.cz(0,1)\n",
        "        self._circuit.cz(1,2)\n",
        "        self._circuit.ry(self.theta_1, 0)\n",
        "        self._circuit.ry(self.theta_2, 1)\n",
        "        self._circuit.ry(self.theta_3, 2)\n",
        "        self._circuit.cz(0,1)\n",
        "        self._circuit.cz(1,2)\n",
        "        self._circuit.ry(self.theta_4, 0)\n",
        "        self._circuit.ry(self.theta_5, 1)\n",
        "        self._circuit.ry(self.theta_6, 2)\n",
        "\n",
        "        self._circuit.measure_all()\n",
        "        # ---------------------------\n",
        "\n",
        "        self.backend = backend\n",
        "        self.shots = shots\n",
        "    \n",
        "    def run(self, thetas):\n",
        "        job = qiskit.execute(self._circuit, \n",
        "                             self.backend, \n",
        "                             shots = self.shots,\n",
        "                             parameter_binds = [{self.theta_0: thetas[0],\n",
        "                                                 self.theta_1: thetas[1],\n",
        "                                                 self.theta_2: thetas[2],\n",
        "                                                 self.theta_3: thetas[3],\n",
        "                                                 self.theta_4: thetas[4],\n",
        "                                                 self.theta_5: thetas[5],\n",
        "                                                 self.theta_6: thetas[6],}])\n",
        "        counts = job.result().get_counts(self._circuit)\n",
        "        \n",
        "        expects = np.zeros(8)\n",
        "        for k in range(8):\n",
        "            key = QC_outputs[k]\n",
        "            perc = counts.get(key, 0) /self.shots\n",
        "            expects[k] = perc\n",
        "        \n",
        "        return expects"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5GNuK9agQ9x"
      },
      "source": [
        "class QuantumCircuit:\n",
        "    def __init__(self, backend, shots):\n",
        "        # circuit definition\n",
        "        self._circuit = qiskit.QuantumCircuit(2)\n",
        "\n",
        "        self.theta_0 = qiskit.circuit.Parameter('theta0')\n",
        "        self.theta_1 = qiskit.circuit.Parameter('theta1')\n",
        "\n",
        "        self._circuit.h(0)\n",
        "        self._circuit.cx(0, 1)\n",
        "        self._circuit.barrier()\n",
        "        self._circuit.ry(self.theta_0, 0)\n",
        "        self._circuit.ry(self.theta_1, 1)\n",
        "        self._circuit.barrier()\n",
        "        self._circuit.h(0)\n",
        "\n",
        "        self._circuit.measure(0, 0)\n",
        "\n",
        "        self.backend = backend\n",
        "        self.shots = shots\n",
        "      \n",
        "    def run(self, thetas):\n",
        "        job = qiskit.execute(self._circuit,\n",
        "                             self.backend,\n",
        "                             shots = self.shots,\n",
        "                             parameter_binds = [{self.theta_0: thetas[0],\n",
        "                                                 self.theta_1: thetas[1]}])\n",
        "        counts = job.result().get_counts(self._circuit)\n",
        "\n",
        "        expects = np.zeros(2)\n",
        "        for k in range(2):\n",
        "            key = QC_outputs[k]\n",
        "            perc = counts.get(key, 0) /self.shots\n",
        "            expects[k] = perc\n",
        "\n",
        "        return expects"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bEBa6XLmTOWo",
        "outputId": "f5aa654f-5ec2-4b7a-e875-695963d62942"
      },
      "source": [
        "# validate bell circuit\n",
        "circuit = QuantumCircuit(qi_qasm, 100)\n",
        "circuit._circuit.draw('mpl')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "CircuitError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m~/anaconda3/envs/quantum/lib/python3.9/site-packages/qiskit/circuit/quantumcircuit.py\u001b[0m in \u001b[0;36m_bit_argument_conversion\u001b[0;34m(bit_representation, in_array)\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0;31m# circuit.h(0) -> circuit.h([qr[0]])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0min_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbit_representation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbit_representation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mCircuitError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-87fa53cabcec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# validate bell circuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcircuit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQuantumCircuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqi_qasm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_circuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mpl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-3b120ea301d1>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, backend, shots)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_circuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_circuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeasure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/quantum/lib/python3.9/site-packages/qiskit/circuit/measure.py\u001b[0m in \u001b[0;36mmeasure\u001b[0;34m(self, qubit, cbit)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcbit\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mcircuit\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \"\"\"\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMeasure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mqubit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcbit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/quantum/lib/python3.9/site-packages/qiskit/circuit/quantumcircuit.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, instruction, qargs, cargs)\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m         \u001b[0mexpanded_qargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqbit_argument_conversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqarg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mqarg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1009\u001b[0;31m         \u001b[0mexpanded_cargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbit_argument_conversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcarg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcarg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0minstructions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInstructionSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/quantum/lib/python3.9/site-packages/qiskit/circuit/quantumcircuit.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m         \u001b[0mexpanded_qargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqbit_argument_conversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqarg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mqarg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1009\u001b[0;31m         \u001b[0mexpanded_cargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbit_argument_conversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcarg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcarg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0minstructions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInstructionSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/quantum/lib/python3.9/site-packages/qiskit/circuit/quantumcircuit.py\u001b[0m in \u001b[0;36mcbit_argument_conversion\u001b[0;34m(self, clbit_representation)\u001b[0m\n\u001b[1;32m    971\u001b[0m             \u001b[0mList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mWhere\u001b[0m \u001b[0meach\u001b[0m \u001b[0mtuple\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mclassical\u001b[0m \u001b[0mbit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \"\"\"\n\u001b[0;32m--> 973\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mQuantumCircuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bit_argument_conversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclbit_representation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclbits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstruction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/quantum/lib/python3.9/site-packages/qiskit/circuit/quantumcircuit.py\u001b[0m in \u001b[0;36m_bit_argument_conversion\u001b[0;34m(bit_representation, in_array)\u001b[0m\n\u001b[1;32m    940\u001b[0m                                                                      type(bit_representation)))\n\u001b[1;32m    941\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCircuitError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Index out of range.'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m             raise CircuitError(\n",
            "\u001b[0;31mCircuitError\u001b[0m: 'Index out of range.'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYvQOEe1xx4-"
      },
      "source": [
        "# Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qHvIGOShqmO"
      },
      "source": [
        "# training data load function\n",
        "def load_training(val_1=0, val_2=1, n_samples=70):\n",
        "    # returns tuple with X_train.data and X_train.targets <-- what I don't have from iris\n",
        "    X_train = datasets.MNIST(root='./data', train=True, download=True,\n",
        "                             transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "    # leave only labels samp_val_1 and samp_val_2\n",
        "    idx = np.append(np.where(X_train.targets == val_1)[0][:n_samples],\n",
        "                    np.where(X_train.targets == val_2)[0][:n_samples])\n",
        "\n",
        "    X_train.data = X_train.data[idx]\n",
        "    X_train.targets = X_train.targets[idx]\n",
        "\n",
        "    # samp vals tunable above in the settings, this is to fit to our data loader\n",
        "    X_train.targets[X_train.targets==val_1] = 0\n",
        "    X_train.targets[X_train.targets==val_2] = 1\n",
        "    ### DEBUG vnv that we remapped the correct samples \n",
        "    #print(\"xtrain targets \", X_train.targets, \"\\n\")\n",
        "\n",
        "    # perform training load\n",
        "    train_loader = DataLoader(X_train, batch_size=1, shuffle=True)\n",
        "\n",
        "    # return loader\n",
        "    return train_loader\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeQWcQ1Ij5N8"
      },
      "source": [
        "# testing data load function\n",
        "def load_testing(val_1=0, val_2=1, n_samples=30):\n",
        "    X_test = datasets.MNIST(root='./data', train=False, download=True,\n",
        "                            transform=transforms.Compose([transforms.ToTensor()]))\n",
        "    # selecting which samples to keep (first 100 0s and 1s)\n",
        "    idx = np.append(np.where(X_test.targets == val_1)[0][:n_samples], \n",
        "                    np.where(X_test.targets == val_2)[0][:n_samples])\n",
        "\n",
        "    X_test.data = X_test.data[idx]\n",
        "    X_test.targets = X_test.targets[idx]\n",
        "\n",
        "    # samp vals tunable above in the settings, to fit to data loader\n",
        "    X_test.targets[X_test.targets==val_1] = 0\n",
        "    X_test.targets[X_test.targets==val_2] = 1\n",
        "    ### DEBUG    \n",
        "    #print(\"xtest targets \", X_train.targets, \"\\n\")\n",
        "\n",
        "    # perform testing load\n",
        "    test_loader = DataLoader(X_test, batch_size=1, shuffle=True)\n",
        "\n",
        "    # return loader\n",
        "    return test_loader\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE8TwpWZx4vH"
      },
      "source": [
        "# CPU Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-XDVxfokKqL"
      },
      "source": [
        "# function to perform model training\n",
        "def perform_training(model, optimizer, loss_func, train_loader, val_1=0, val_2=1, epochs=5):\n",
        "    # start training timer\n",
        "    start_train = time.time()\n",
        "\n",
        "    loss_list = [] # store loss history\n",
        "    model.train()  # place model in training mode\n",
        "    print('\\nBegin training for samples {0} and {1}:'.format(val_1, val_2))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print('Starting epoch {} for 2 qubits'.format(epoch))\n",
        "        total_loss = []\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad(set_to_none=True) # init gradient\n",
        "            output = model(data)             # forward pass\n",
        "            ### DEBUG\n",
        "            #print(\"target is: \", target)\n",
        "            #print(\"output is: \", output)\n",
        "            loss = loss_func(output, target) # calc loss\n",
        "            loss.backward()                  # backward pass\n",
        "            optimizer.step()                 # optimize weights\n",
        "            total_loss.append(loss.item())   # store loss\n",
        "        loss_list.append(sum(total_loss)/len(total_loss))\n",
        "        print('Training [{:0f}%]\\tLoss: {:.4f}'.format(\n",
        "              100. * (epoch + 1) / epochs, loss_list[-1]))\n",
        "        \n",
        "    # finish training timer, report training runtime\n",
        "    end_train = time.time()\n",
        "    print('Training runtime is: ', (end_train - start_train)/60, ' min')\n",
        "        \n",
        "    # plot results of cost reduction\n",
        "    plt.figure()\n",
        "    plt.plot(loss_list)\n",
        "    plt.title('Cost Reduction for 2 qubits between {0} and {1}:'.format(val_1, val_2))\n",
        "    plt.xlabel('Training Iterations ({0} epochs)'.format(epochs))\n",
        "    plt.ylabel('Cross Entropy Loss')\n",
        "    plt.show()\n",
        "\n",
        "    return total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVjOChTQyExJ"
      },
      "source": [
        "# function to test and evaluate model\n",
        "def perform_eval(model, loss_func, test_loader, total_loss, val_1=0, val_2=1):\n",
        "    # start eval time\n",
        "    start_eval = time.time()\n",
        "\n",
        "    model.eval() # set into eval mode\n",
        "    print('Begin eval for samples {0} and {1}:'.format(val_1, val_2))\n",
        "\n",
        "    with no_grad():\n",
        "        correct = 0\n",
        "        for batch_idx, (data, target) in enumerate(test_loader):\n",
        "            output = model(data)\n",
        "            if len(output.shape) == 1:\n",
        "                output = output.reshape(1, *output.shape)\n",
        "            \n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        \n",
        "            loss = loss_func(output, target)\n",
        "            total_loss.append(loss.item())\n",
        "        # batch_size goes where the 1 is here\n",
        "        print('Performance on test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%'\n",
        "              .format(sum(total_loss) / len(total_loss),\n",
        "              correct / len(test_loader) / 1 * 100))\n",
        "\n",
        "    # commenting this out because it reports it at a strange time in the console\n",
        "    # cool visual, but doesn't work as expected, maybe put into a different function?\n",
        "    \"\"\"    \n",
        "    # show handful of examples for 2 qubit system\n",
        "    n_samples_show = 6\n",
        "    count = 0\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
        "\n",
        "    model.eval()\n",
        "    with no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(test_loader):\n",
        "            if count == n_samples_show:\n",
        "                break\n",
        "            output = model(data)\n",
        "        \n",
        "            pred = output.argmax(dim=1, keepdim=True) \n",
        "        \n",
        "            # remap class values to samp_val 1 and 2\n",
        "            # where pred == 0 set it to samp_val_1, same for pred == 1\n",
        "            # below lines don't work for this, need to figure out another way but not critical\n",
        "            #pred.item[pred.item()==0] = samp_val_1\n",
        "            #pred.item[pred.item()==1] = samp_val_2\n",
        "\n",
        "            axes[count].imshow(data[0].numpy().squeeze(), cmap='gray')\n",
        "            axes[count].set_xticks([])\n",
        "            axes[count].set_yticks([])\n",
        "            axes[count].set_title('Predicted {}'.format(pred.item()))\n",
        "        \n",
        "            count += 1    \n",
        "    \"\"\"  \n",
        "    \n",
        "    # end eval time\n",
        "    end_eval = time.time()\n",
        "    print('Evaluation time is: ', (end_eval - start_eval)/60, ' min')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FquITpfyyBED"
      },
      "source": [
        "# GPU Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jj0ANaPw5n6h"
      },
      "source": [
        "def perform_training_gpu(model, optimizer, loss_func, train_loader, val_1=0, val_2=1, epochs=5):\n",
        "    # start training timer\n",
        "    start_train = time.time()\n",
        "\n",
        "    loss_list = [] # store loss history\n",
        "    model.train()  # place model in training mode\n",
        "    print('\\nBegin training for samples {0} and {1}:'.format(val_1, val_2))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print('Starting epoch {} for 2 qubits'.format(epoch))\n",
        "        total_loss = []\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad(set_to_none=True) # init gradient\n",
        "\n",
        "            # gpu optimize data and target tensors\n",
        "            data = data.cuda()\n",
        "            target = target.cuda()\n",
        "\n",
        "            output = model(data).cuda()             # forward pass\n",
        "            ### DEBUG\n",
        "            #print(\"target is: \", target)\n",
        "            #print(\"output is: \", output)\n",
        "            \n",
        "            loss = loss_func(output, target) # calc loss\n",
        "            loss.backward()                  # backward pass\n",
        "            optimizer.step()                 # optimize weights\n",
        "            total_loss.append(loss.item())   # store loss\n",
        "        loss_list.append(sum(total_loss)/len(total_loss))\n",
        "        print('Training [{:0f}%]\\tLoss: {:.4f}'.format(\n",
        "              100. * (epoch + 1) / epochs, loss_list[-1]))\n",
        "        \n",
        "    # finish training timer, report training runtime\n",
        "    end_train = time.time()\n",
        "    print('Training runtime is: ', (end_train - start_train)/60, ' min')\n",
        "        \n",
        "    # plot results of cost reduction\n",
        "    plt.figure()\n",
        "    plt.plot(loss_list)\n",
        "    plt.title('Cost Reduction for 2 qubits between {0} and {1}:'.format(val_1, val_2))\n",
        "    plt.xlabel('Training Iterations ({0} epochs)'.format(epochs))\n",
        "    plt.ylabel('Cross Entropy Loss')\n",
        "    plt.show()\n",
        "\n",
        "    return total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG9lO-H67BBJ"
      },
      "source": [
        "# function to test and evaluate model\n",
        "def perform_eval_gpu(model, loss_func, test_loader, total_loss, val_1=0, val_2=1):\n",
        "    # start eval time\n",
        "    start_eval = time.time()\n",
        "\n",
        "    model.eval() # set into eval mode\n",
        "    print('Begin eval for samples {0} and {1}:'.format(val_1, val_2))\n",
        "\n",
        "    with no_grad():\n",
        "        correct = 0\n",
        "        for batch_idx, (data, target) in enumerate(test_loader):\n",
        "\n",
        "            # optimize for gpu acceleration\n",
        "            data = data.cuda()\n",
        "            target = target.cuda()\n",
        "\n",
        "            output = model(data).cuda()\n",
        "\n",
        "            if len(output.shape) == 1:\n",
        "                output = output.reshape(1, *output.shape)\n",
        "            \n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        \n",
        "            loss = loss_func(output, target)\n",
        "            total_loss.append(loss.item())\n",
        "        # batch_size goes where the 1 is here\n",
        "        print('Performance on test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%'\n",
        "              .format(sum(total_loss) / len(total_loss),\n",
        "              correct / len(test_loader) / 1 * 100))\n",
        "\n",
        "    # commenting this out because it reports it at a strange time in the console\n",
        "    # cool visual, but doesn't work as expected, maybe put into a different function?\n",
        "    \"\"\"    \n",
        "    # show handful of examples for 2 qubit system\n",
        "    n_samples_show = 6\n",
        "    count = 0\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
        "\n",
        "    model.eval()\n",
        "    with no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(test_loader):\n",
        "            if count == n_samples_show:\n",
        "                break\n",
        "            output = model(data)\n",
        "        \n",
        "            pred = output.argmax(dim=1, keepdim=True) \n",
        "        \n",
        "            # remap class values to samp_val 1 and 2\n",
        "            # where pred == 0 set it to samp_val_1, same for pred == 1\n",
        "            # below lines don't work for this, need to figure out another way but not critical\n",
        "            #pred.item[pred.item()==0] = samp_val_1\n",
        "            #pred.item[pred.item()==1] = samp_val_2\n",
        "\n",
        "            axes[count].imshow(data[0].numpy().squeeze(), cmap='gray')\n",
        "            axes[count].set_xticks([])\n",
        "            axes[count].set_yticks([])\n",
        "            axes[count].set_title('Predicted {}'.format(pred.item()))\n",
        "        \n",
        "            count += 1    \n",
        "    \"\"\"\n",
        "\n",
        "    # end eval time\n",
        "    end_eval = time.time()\n",
        "    print('Evaluation time is: ', (end_eval - start_eval)/60, ' min')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKbevbobyM7M"
      },
      "source": [
        "# QNN Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40wWGtSyuipl"
      },
      "source": [
        "# set up QNN elements\n",
        "num_inputs = 2\n",
        "\n",
        "# ZZ is 2nd order Pauli expansion circuit\n",
        "fm = ZZFeatureMap(num_inputs)\n",
        "#fm.draw(output='mpl')\n",
        "\n",
        "# RealAmplitudes is used as an ansatz for ML, heuristic trial wave func\n",
        "ansatz = RealAmplitudes(num_inputs, reps=1)\n",
        "#ansatz.draw(output='mpl')\n",
        "\n",
        "# define observable\n",
        "observable = PauliSumOp.from_list([('Z'*num_inputs, 1)])\n",
        "#print(observable)\n",
        "\n",
        "# define two layer QNN\n",
        "qnn = TwoLayerQNN(num_inputs, \n",
        "                  feature_map=fm, \n",
        "                  ansatz=ansatz, \n",
        "                  observable=observable,\n",
        "                  quantum_instance=qi)\n",
        "#print(qnn.operator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CAO_Twwu0rm"
      },
      "source": [
        "class Net(Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = Conv2d(1, 2, kernel_size=5)\n",
        "        self.conv2 = Conv2d(2, 16, kernel_size=5)\n",
        "        self.dropout = Dropout2d()\n",
        "        self.fc1 = Linear(256, 64)\n",
        "        self.fc2 = Linear(64, 2)         # 2-dimensional input to QNN\n",
        "        self.qnn = TorchConnector(qnn)\n",
        "        self.fc3 = Linear(1, 1)          # 1-dimensional output from QNN\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout(x)\n",
        "        x = x.view(1, -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = x.cpu()\n",
        "        print('x type is: ', type(x))\n",
        "        x = self.qnn(x)  # apply QNN\n",
        "        # typecast qnn output to a cuda tensor\n",
        "        #x = x.type(dtype=torch.cuda.FloatTensor)\n",
        "        x = self.fc3(x)\n",
        "        return cat((x, 1 - x), -1)\n",
        "\n",
        "if gpu:\n",
        "    model = Net().cuda()\n",
        "else:\n",
        "    model = Net()\n",
        "\n",
        "#summary(model, (1, 28, 28))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXMDmuNhwNOL"
      },
      "source": [
        "# define model, optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "if gpu:\n",
        "    loss_func = CrossEntropyLoss().cuda()\n",
        "else:\n",
        "    loss_func = CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1akcDqXyQ2i"
      },
      "source": [
        "# Main Program"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "I_qs_6zFrBjF",
        "outputId": "4fec7786-f48d-4971-d0e8-7ae61bf1a052"
      },
      "source": [
        "# total program runtime\n",
        "start_eval = time.time()\n",
        "\n",
        "acc_vals = []\n",
        "\n",
        "# main program loop I guess?\n",
        "for i in data_set:\n",
        "    # want to exclude 9 to avoid repeats\n",
        "    if i != 9:\n",
        "        # iterate through indices larger than i to create subset\n",
        "        for j in data_set:\n",
        "            if j > i:\n",
        "                subset = [i, j]\n",
        "\n",
        "                # load a subset of data for training\n",
        "                trn_load = load_training(i, j, 210)\n",
        "                # load subset for testing\n",
        "                tst_load = load_testing(i, j, 90)\n",
        "\n",
        "                ### DEBUG\n",
        "                print(\"model is: \", type(model))\n",
        "                print(\"optim is: \", type(optimizer))\n",
        "                print(\"loss func is: \", type(loss_func))\n",
        "                print(\"test load is: \", type(tst_load))\n",
        "                print(\"type of i is: \", type(i))\n",
        "                print(\"type of j is: \", type(j))\n",
        "                print(\"type of epoch is: \", type(epochs))\n",
        "\n",
        "                # start training for subset\n",
        "                if gpu:\n",
        "                    tot_loss = perform_training_gpu(model, optimizer, loss_func, tst_load, i, j, epochs)\n",
        "                else:\n",
        "                    tot_loss = perform_training(model, optimizer, loss_func, tst_load, i, j, epochs)\n",
        "\n",
        "                ### DEBUG\n",
        "                print(\"tot loss type is: \", type(tot_loss))\n",
        "\n",
        "                # then evaluate model for subset\n",
        "                if gpu:\n",
        "                    perform_eval_gpu(model, loss_func, tst_load, tot_loss, i, j)\n",
        "                else:\n",
        "                    perform_eval(model, loss_func, tst_load, tot_loss, i, j)\n",
        "\n",
        "                # add a data structure to hold the accuracy values for each set of elements\n",
        "\n",
        "\n",
        "\n",
        "# end eval time\n",
        "end_eval = time.time()\n",
        "print('Total program runtime is: ', (end_eval - start_eval)/60, ' min')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model is:  <class '__main__.Net'>\n",
            "optim is:  <class 'torch.optim.adam.Adam'>\n",
            "loss func is:  <class 'torch.nn.modules.loss.CrossEntropyLoss'>\n",
            "test load is:  <class 'torch.utils.data.dataloader.DataLoader'>\n",
            "type of i is:  <class 'int'>\n",
            "type of j is:  <class 'int'>\n",
            "type of epoch is:  <class 'int'>\n",
            "\n",
            "Begin training for samples 0 and 1:\n",
            "Starting epoch 0 for 2 qubits\n",
            "x type is:  <class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/home/zero/anaconda3/envs/quantum/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-54ea5f51843c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0;31m# start training for subset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                     \u001b[0mtot_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperform_training_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtst_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mtot_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperform_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtst_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-f440988b15b0>\u001b[0m in \u001b[0;36mperform_training_gpu\u001b[0;34m(model, optimizer, loss_func, train_loader, val_1, val_2, epochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m             \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0;31m### DEBUG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m#print(\"target is: \", target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/quantum/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-79f533cac9c1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x type is: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# apply QNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;31m# typecast qnn output to a cuda tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#x = x.type(dtype=torch.cuda.FloatTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/quantum/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/quantum/lib/python3.9/site-packages/qiskit_machine_learning/connectors/torch_connector.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \"\"\"\n\u001b[1;32m    224\u001b[0m         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minput_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         return TorchConnector._TorchNNFunction.apply(input_, self._weights,\n\u001b[0m\u001b[1;32m    226\u001b[0m                                                      self._neural_network, self._sparse)\n",
            "\u001b[0;32m~/anaconda3/envs/quantum/lib/python3.9/site-packages/qiskit_machine_learning/connectors/torch_connector.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, input_data, weights, neural_network, sparse)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneural_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mneural_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSparseArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'coo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_1iCedewj2r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}